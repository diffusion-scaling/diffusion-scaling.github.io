<!DOCTYPE html>
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">

    <meta charset="utf-8">
    <meta property="og:title" content="Diffusion Beats Autoregressive in Data-Constrained Settings" />
    <meta property="og:description" content="Masked diffusion models significantly outperform autoregressive models when compute is abundant but data is scarce." />
    <meta property="og:url" content="https://diffusion-data-constraint.github.io/" />
    <meta property="og:image" content="https://diffusion-data-constraint.github.io/static/images/preview.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="628" />
    <meta name="description"
        content="Masked diffusion models significantly outperform autoregressive models when compute is abundant but data is scarce, achieving lower validation loss and superior downstream performance." />
    <meta name="keywords"
        content="diffusion models, autoregressive models, data-constrained settings, language models, scaling laws, data efficiency, compute efficiency" />
    <meta name="viewport" content="initial-scale=1" />
    <!-- twitter -->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Diffusion Beats Autoregressive in Data-Constrained Settings" />
    <meta name="twitter:description"
        content="Masked diffusion models significantly outperform autoregressive models when compute is abundant but data is scarce." />
    <meta name="twitter:url" content="https://diffusion-data-constraint.github.io/" />
    <meta name="twitter:image" content="https://diffusion-data-constraint.github.io/static/images/preview.png" />
    <meta name="twitter:site" content="@pathak2206" />
    <meta name="twitter:image:src" content="https://diffusion-data-constraint.github.io/static/images/preview.png" />
    <meta name="twitter:image_alt" content="Diffusion vs Autoregressive Models" />

    <title>Diffusion Beats Autoregressive in Data-Constrained Settings</title>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-RYWGEJGP6S"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-RYWGEJGP6S');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="stylesheet" href="https://use.typekit.net/iag3ven.css">

    <link rel="stylesheet" href="./static/css/prism.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/prism.min.js">
    </script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs-bibtex@2.0.1/prism-bibtex.min.js">
    </script>

    <link rel="icon"
        href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ”„</text></svg>">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://d3js.org/d3.v3.min.js" charset="utf-8"></script>
    <script src="https://d3js.org/topojson.v1.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>

    <!-- mathjax -->
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [['$','$'], ['\\(','\\)']],
                processEscapes: true
            }
        });
    </script>

</head>

<body>
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <p style="padding: 20px;" />
                        <h1 class="title is-1 publication-title" style=" white-space: nowrap;">
                            <span id="main-title">
                                Diffusion Beats Autoregressive in Data-Constrained Settings
                            </span>
                        </h1>
                        <div class="is-size-5 publication-authors" style="line-height: 2.2; font-weight: 500; white-space: nowrap;">
                            <span class="author-block">
                                <a href="https://mihirp1998.github.io/" target="_blank" class="author-name">Mihir Prabhudesai</a><sup>*</sup>
                            </span>
                            &nbsp;&nbsp;
                            <span class="author-block">
                                <a href="https://www.linkedin.com/in/mengning-wu-2ba8562ba/" target="_blank" class="author-name">Menging Wu</a><sup>*</sup>
                            </span>
                            &nbsp;&nbsp;
                            <span class="author-block">
                                <a href="https://www.linkedin.com/in/amir-zadeh-894921320" target="_blank" class="author-name">Amir Zadeh</a>
                            </span>
                            &nbsp;&nbsp;
                            <span class="author-block">
                                <a href="https://www.cs.cmu.edu/~katef/" target="_blank" class="author-name">Katerina Fragkiadaki</a>
                            </span>
                            &nbsp;&nbsp;
                            <span class="author-block">
                                <a href="https://www.cs.cmu.edu/~dpathak/" target="_blank" class="author-name">Deepak Pathak</a>
                            </span>
                        </div>
                        <p style="padding: 0.2rem;" />
                        <div class="is-size-5 publication-authors">
                            <span class="author-block" style="color: #252525;">Carnegie Mellon University &nbsp;&nbsp;&nbsp; Lambda</span><br>
                            <br style="line-height: 2px" />
                            <span class="author-block" style="font-size: 0.8em; color: #252525; font-style: italic;"><sup>*</sup>Equal contribution</span>
                        </div>

                        <p style="padding: 10px;" />

                        <div class="buttons is-centered">
                            <button class="external-link button is-medium is-ghost publication-links is-rounded">
                                <a href="#" target="_blank"
                                    style="text-decoration:none;">
                                    <span class="icon is-small">
                                        <i class="ai ai-arxiv"></i>
                                    </span>
                                    <span>arXiv</span>
                                </a>
                            </button>
                            <button class="external-link button is-medium is-ghost publication-links is-rounded">
                                <a href="./static/docs/diffusion_data_constraint.pdf" target="_blank">
                                    <span class="icon is-small">
                                        <i class="fas fa-file-pdf"></i>
                                    </span>
                                    <span>pdf</span>
                                </a>
                            </button>
                            
                            <button class="external-link button is-medium is-ghost publication-links is-rounded">
                                <a href="https://github.com/wmn-231314/diffusion-data-constraint" target="_blank">
                                    <span class="icon is-small">
                                        <i class="fab fa-github"></i>
                                    </span>
                                    <span>code</span>
                                </a>
                            </button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- hack to pull the below up vertically -->
    <span style="display:block; margin-top:-1.75em;"/>

    <!-- Method Overview -->
    <section class="section" id="method-overview">
        <div class="container is-max-widescreen">
            <div class="columns is-centered has-text-centered">
                <div class="column" style="border-radius: 10px; background-color: rgb(255,255,255)">
                    <p style="padding: 10px;" />
                    <div id="method-overview-wrapper">
                        <img src="./static/images/fig1_50_100.png" alt="Diffusion vs AR Pareto frontier in data-constrained settings."
                        class="method-overview-full-img method-overview" draggable="false" />                        
                    </div>
                    <p style="padding: 10px;" />
                    <div class="method-overview-text has-text-justified">
                        <p>
                            We systematically study <strong>masked diffusion models</strong> versus <strong>autoregressive (AR) models</strong> 
                            in data-constrained settingsâ€”where training involves repeated passes over limited data. While AR models 
                            initially outperform diffusion models at low compute (particularly near the Chinchilla-optimal point), 
                            this advantage disappears as training continues beyond this regime. When data must be reused across 
                            multiple epochs, <strong>diffusion models significantly outperform AR models</strong>, achieving lower 
                            validation loss and superior downstream performance. We attribute this to implicit data augmentation: 
                            masked diffusion exposes the model to diverse token orderings and prediction tasks, unlike AR's fixed 
                            left-to-right factorization.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!--/ Method Overview -->

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-three-quarters">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Autoregressive (AR) models have long dominated the landscape of large language models, driving 
                            progress across a wide range of tasks. Recently, diffusion-based language models have emerged 
                            as a promising alternative, though their advantages over AR models remain underexplored. In this 
                            paper, we systematically study masked diffusion models in data-constrained settingsâ€”where training 
                            involves repeated passes over limited dataâ€”and find that they significantly outperform AR models 
                            when compute is abundant but data is scarce. Diffusion models make better use of repeated data, 
                            achieving lower validation loss and superior downstream performance. We interpret this advantage 
                            as implicit data augmentation: masked diffusion exposes the model to a diverse distribution of 
                            token orderings and prediction tasks, unlike AR's fixed left-to-right factorization. We find new 
                            scaling laws for diffusion models and derive a closed-form expression for the critical compute 
                            threshold at which diffusion begins to outperform AR. These results suggest that when data, not 
                            compute, is the bottleneck, diffusion models offer a compelling alternative to the standard AR paradigm.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Abstract. -->
        </div>
    </section>

    <p style="padding: 20px;" />

    <!-- Key Findings -->
    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-three-quarters">
                    <h2 class="title is-3">Key Findings</h2>
                    <div class="content has-text-justified">
                        <p><strong>1. Diffusion models surpass autoregressive models given sufficient compute.</strong> 
                        Across a wide range of unique token budgets, AR models initially outperform diffusion models at low compute, 
                        but quickly saturate. Beyond a critical compute threshold, diffusion models continue improving and ultimately 
                        achieve better performance. <a href="#method-overview">(See Figure 1)</a></p>
                        
                        <p><strong>2. Diffusion models benefit far more from repeated data.</strong> 
                        While AR models can effectively use repeated data for up to 4 epochs, diffusion models can be trained 
                        on repeated data for up to <strong>100 epochs</strong> with repeated data almost as effective as fresh data. 
                        <a href="#contour-plots">(See Figure 2)</a> &amp; <a href="#data-value-decay">(Figure 3)</a> &amp; <a href="#extrapolated-epochs">(Figure 5, extrapolated)</a></p>
                        
                        <p><strong>3. Diffusion models have a much higher effective epoch count.</strong> 
                        We find \(R_D^* \approx 500\) for diffusion models compared to \(R_D^* \approx 15\) for AR models, 
                        suggesting diffusion models can benefit from repeated data over far more epochs without major degradation. 
                        <a href="#training-curves">(See Figure 4)</a></p>
                        
                        <p><strong>4. Critical compute point follows a power law with dataset size.</strong> 
                        We derive a closed-form expression \(C_{\text{crit}}(U) = 2.12 \times 10^{15} \cdot U^{2.174}\) 
                        that predicts when diffusion becomes the favorable modeling choice for any given dataset size. 
                        <a href="#critical-compute">(See Figure 6)</a></p>
                        
                        <p><strong>5. Diffusion models yield better downstream performance.</strong> 
                        The validation loss improvements translate to consistent gains across diverse downstream language tasks. 
                        <a href="#downstream-results">(See Table 2)</a></p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <p style="padding: 20px;" />

    <!-- Contour Plots -->
    <section class="section" id="contour-plots">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-three-quarters">
                    <h2 class="title is-3">Validation Loss Contours: AR vs Diffusion</h2>
                    <div class="content has-text-justified">
                        <p>
                            We analyze the trade-off between model parameters and training epochs. The contour plots below 
                            show validation loss as a function of both axes for 100M unique tokens. Diffusion models achieve 
                            their best loss at 500 epochs, while AR models reach their best at just 50 epochs. AR models 
                            begin to overfit at high epoch counts, while diffusion models show no signs of overfitting.
                        </p>
                    </div>
                </div>
            </div>
            
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-half">
                        <figure>
                            <img src="./static/images/autoregressive_contour.png" alt="AR validation loss contour" 
                                draggable="false" />
                            <figcaption class="has-text-centered">
                                <strong>Autoregressive:</strong> Best loss at 50 epochs (3.71)
                            </figcaption>
                        </figure>
                    </div>
                    <div class="column is-half">
                        <figure>
                            <img src="./static/images/diffusion_contour.png" alt="Diffusion validation loss contour" 
                                draggable="false" />
                            <figcaption class="has-text-centered">
                                <strong>Diffusion:</strong> Best loss at 500 epochs (3.55)
                            </figcaption>
                        </figure>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Data Value Decay -->
    <section class="section" id="data-value-decay">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-three-quarters">
                    <h2 class="title is-3">Data Value Decay with Repetition</h2>
                    <div class="content has-text-justified">
                        <p>
                            We evaluate how the utility of unique data decays with increased repetition across different 
                            compute budgets. Diffusion models consistently exhibit a substantially slower decay rate than 
                            AR models, suggesting they are better able to extract value from repeated data.
                        </p>
                    </div>
                </div>
            </div>
            
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-three-fourths">
                        <figure>
                            <img src="./static/images/fig5_b.png" alt="Data value decay analysis" 
                                draggable="false" />
                            <figcaption class="has-text-centered">
                                Decay rate of data value under repetition. Diffusion models show much slower decay, 
                                reflecting greater robustness to data repetition.
                            </figcaption>
                        </figure>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Training Curves -->
    <section class="section" id="training-curves">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-three-quarters">
                    <h2 class="title is-3">Training Curves: Robustness to Data Repetition</h2>
                    <div class="content has-text-justified">
                        <p>
                            Training curves for different epoch counts using the same total compute show that AR models 
                            overfit with increased repetition (diverging loss curves), while diffusion models exhibit 
                            overlapping curves, indicating much greater robustness to data repetition. We also show 
                            extrapolated scaling behavior demonstrating that diffusion models can effectively use 
                            repeated data for up to 100 epochs compared to only 4 epochs for AR models.
                        </p>
                    </div>
                </div>
            </div>
            
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-half">
                        <figure>
                            <img src="./static/images/training_curve_arm_smooth.png" alt="AR training curves" 
                                draggable="false" />
                            <figcaption class="has-text-centered">
                                <strong>AR:</strong> Validation loss rises with more epochs (overfitting)
                            </figcaption>
                        </figure>
                    </div>
                    <div class="column is-half">
                        <figure>
                            <img src="./static/images/training_curve_mdm_smooth.png" alt="Diffusion training curves" 
                                draggable="false" />
                            <figcaption class="has-text-centered">
                                <strong>Diffusion:</strong> Curves nearly unchanged, robust to repetition
                            </figcaption>
                        </figure>
                    </div>
                </div>
            </div>
            
            <!-- Extrapolated Scaling Curves -->
            <div class="container is-max-desktop" id="extrapolated-scaling-curves">
                <div class="columns is-centered">
                    <div class="column is-three-fourths">
                        <figure>
                            <img src="./static/images/extrapolate.png" alt="Extrapolated scaling curves" 
                                draggable="false" />
                            <figcaption class="has-text-centered">
                                <strong>Extrapolated scaling behavior:</strong> AR models benefit from repeated data up to ~4 epochs, 
                                while diffusion models benefit up to ~100 epochs.
                            </figcaption>
                        </figure>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Critical Compute Analysis -->
    <section class="section" id="critical-compute">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-three-quarters">
                    <h2 class="title is-3">When to Use Diffusion over AR?</h2>
                    <div class="content has-text-justified">
                        <p>
                            We derive a critical compute frontier that follows a power law: 
                            \(C_{\text{crit}}(U) \propto U^{2.174}\). This gives practitioners 
                            a clear guideline for when diffusion models should be preferred over autoregressive models.
                        </p>
                    </div>
                </div>
            </div>
            
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-half">
                        <figure>
                            <img src="./static/images/heatmap.png" alt="Loss gap heatmap" 
                                draggable="false" />
                            <figcaption class="has-text-centered">
                                <strong>Loss Gap Heatmap:</strong> Red regions show where diffusion outperforms AR
                            </figcaption>
                        </figure>
                    </div>
                    <div class="column is-half">
                        <figure>
                            <img src="./static/images/isoflops_fit2.png" alt="Critical compute curve" 
                                draggable="false" />
                            <figcaption class="has-text-centered">
                                <strong>Critical Compute Curve:</strong> Power law relationship \(C_{\text{crit}}(U) \propto U^{2.174}\)
                            </figcaption>
                        </figure>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Downstream Results -->
    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-three-quarters">
                    <h2 class="title is-3">Downstream Performance</h2>
                    <div class="content has-text-justified">
                        <p>
                            We evaluate the best-performing models on diverse downstream benchmarks. Across tasks and 
                            data scales, diffusion models consistently achieve higher accuracy than their AR counterparts, 
                            validating that the data efficiency gains in validation loss translate into stronger downstream performance.
                        </p>
                    </div>
                </div>
            </div>
            
            <div class="container is-max-desktop">
                <div class="table-container">
                    <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
                        <caption style="caption-side: top; padding: 10px 0; font-weight: bold;">
                            Downstream Results: Best AR vs Diffusion models in data-constrained settings
                        </caption>
                        <thead>
                            <tr>
                                <th class="has-text-centered">Benchmarks</th>
                                <th class="has-text-centered">Random Baseline</th>
                                <th class="has-text-centered" colspan="2">100M unique tokens</th>
                                <th class="has-text-centered" colspan="2">500M unique tokens</th>
                            </tr>
                            <tr>
                                <th></th>
                                <th></th>
                                <th class="has-text-centered">AR</th>
                                <th class="has-text-centered">Diffusion</th>
                                <th class="has-text-centered">AR</th>
                                <th class="has-text-centered">Diffusion</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>ARC-Easy</td>
                                <td class="has-text-centered">25.00</td>
                                <td class="has-text-centered">35.63</td>
                                <td class="has-text-centered has-text-weight-bold">37.84</td>
                                <td class="has-text-centered">43.79</td>
                                <td class="has-text-centered has-text-weight-bold">45.95</td>
                            </tr>
                            <tr>
                                <td>BoolQ</td>
                                <td class="has-text-centered">50.00</td>
                                <td class="has-text-centered">46.00</td>
                                <td class="has-text-centered has-text-weight-bold">49.38</td>
                                <td class="has-text-centered">51.87</td>
                                <td class="has-text-centered has-text-weight-bold">55.26</td>
                            </tr>
                            <tr>
                                <td>COPA</td>
                                <td class="has-text-centered">50.00</td>
                                <td class="has-text-centered">56.33</td>
                                <td class="has-text-centered has-text-weight-bold">59.00</td>
                                <td class="has-text-centered has-text-weight-bold">67.00</td>
                                <td class="has-text-centered">64.83</td>
                            </tr>
                            <tr>
                                <td>HellaSwag</td>
                                <td class="has-text-centered">25.00</td>
                                <td class="has-text-centered">27.37</td>
                                <td class="has-text-centered has-text-weight-bold">30.24</td>
                                <td class="has-text-centered">32.28</td>
                                <td class="has-text-centered has-text-weight-bold">35.33</td>
                            </tr>
                            <tr>
                                <td>PiQA</td>
                                <td class="has-text-centered">50.00</td>
                                <td class="has-text-centered has-text-weight-bold">60.94</td>
                                <td class="has-text-centered">60.72</td>
                                <td class="has-text-centered has-text-weight-bold">65.71</td>
                                <td class="has-text-centered">65.61</td>
                            </tr>
                            <tr>
                                <td>RACE</td>
                                <td class="has-text-centered">25.00</td>
                                <td class="has-text-centered">25.28</td>
                                <td class="has-text-centered has-text-weight-bold">28.96</td>
                                <td class="has-text-centered">28.28</td>
                                <td class="has-text-centered has-text-weight-bold">31.44</td>
                            </tr>
                            <tr>
                                <td>WinoGrande XL</td>
                                <td class="has-text-centered">50.00</td>
                                <td class="has-text-centered">48.87</td>
                                <td class="has-text-centered has-text-weight-bold">50.97</td>
                                <td class="has-text-centered">50.61</td>
                                <td class="has-text-centered has-text-weight-bold">51.51</td>
                            </tr>
                            <tr>
                                <td>SciQ</td>
                                <td class="has-text-centered">25.00</td>
                                <td class="has-text-centered">58.05</td>
                                <td class="has-text-centered has-text-weight-bold">68.67</td>
                                <td class="has-text-centered">67.82</td>
                                <td class="has-text-centered has-text-weight-bold">79.13</td>
                            </tr>
                            <tr>
                                <td>Lambada</td>
                                <td class="has-text-centered">00.00</td>
                                <td class="has-text-centered">10.91</td>
                                <td class="has-text-centered has-text-weight-bold">15.19</td>
                                <td class="has-text-centered">15.07</td>
                                <td class="has-text-centered has-text-weight-bold">22.30</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
        </div>
    </section>

    <!-- Takeaway -->
    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-three-quarters">
                    <h2 class="title is-3">Key Takeaway</h2>
                    <div class="content has-text-justified">
                        <div style="background-color: #f5f5f5; padding: 20px; border-radius: 10px; text-align: center;">
                            <!-- <p style="font-size: 1.2em;  margin-bottom: 10px;">
                                For practitioners, our takeaway is simple:
                            </p> -->
                            <p style="font-size: 1.1em; font-style: italic;">
                                If you are compute-constrained, use autoregressive models;<br>
                                if you are data-constrained, use diffusion models.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- <section class="section" id="paper">
        <div class="container is-mobile">
            <div class="columns is-centered has-text-centered">
                <div class="container content">
                    <h2 class="title is-3">BibTeX</h2>
                    <div id="bibtex" class="column has-text-justified is-centered">
                        <pre><code class="language-bibtex">@article{prabhudesai2025diffusion,
    title={Diffusion Beats Autoregressive in Data-Constrained Settings},
    author={Prabhudesai, Mihir and Wu, Menging and Zadeh, Amir and Fragkiadaki, Katerina and Pathak, Deepak},
    journal={arXiv preprint arXiv:2502.01491},
    year={2025}
}</code></pre>
                    </div>
                </div>
            </div>
        </div>
    </section> -->

    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="https://arxiv.org/abs/2502.01491" target="_blank">
                    <i class="ai ai-arxiv"></i>
                </a>
                &nbsp;
                <a class="icon-link" href="./static/docs/diffusion_data_constraint.pdf" target="_blank">
                    <i class="fas fa-file-pdf"></i>
                </a>
                &nbsp;
                <a class="icon-link" href="https://github.com/wmn-231314/diffusion-data-constraint" target="_blank">
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="content">
                    <p>
                        Page source code was adapted from
                        <a href="https://nerfies.github.io" target="_blank">here</a>
                        and
                        <a href="https://diffusion-classifier.github.io" target="_blank">here</a>.
                    </p>
                </div>
            </div>
        </div>
    </footer>

    <script src="./static/js/index.js"></script>
    <script src="./static/js/prism.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs-bibtex@2.0.1/prism-bibtex.js"
        integrity="sha256-+dK6uqUp/DnP6ef97s8XcoynBnGe5vM5gvBECH0EB3U=" crossorigin="anonymous">
        </script>
</body>